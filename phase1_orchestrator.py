# phase1_orchestrator.py
# Phase 1 - TSETMC WebAPI Layer & Real-time Caching (Orchestrator)

import pytse_client as tse
from typing import Dict, Any, List, Optional
import logging
import redis
import json
import os
from dotenv import load_dotenv

# --- Import DB Components ---
# ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ db_connector Ø¯Ø± Ú©Ù†Ø§Ø± Ù‡Ù…ÛŒÙ† ÙØ§ÛŒÙ„ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯
from db_connector import (
    get_db_session, 
    WeeklyWatchlistResult, 
    GoldenKeyResult, 
    PotentialBuyQueueResult, 
    DynamicSupportOpportunity
)

logger = logging.getLogger(__name__)

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Redis ---
load_dotenv()
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))
REALTIME_CACHE_KEY = "market:realtime:tickers" 

class Phase1Orchestrator:
    """
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Orchestrator Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ ÙˆØ¸Ø§ÛŒÙ Ø²ÛŒØ± Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:
    1. Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Backend (Ú†Ù‡Ø§Ø± Ø¬Ø¯ÙˆÙ„ Ø§ØµÙ„ÛŒ).
    2. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„Ø§Ù‹ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø§Ø² TSETMC (Ø´Ø§Ù…Ù„ Ø­Ù‚ÛŒÙ‚ÛŒ/Ø­Ù‚ÙˆÙ‚ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ).
    3. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± Redis Ø¨Ø±Ø§ÛŒ Ù…ØµØ±Ù ÙØ§Ø²Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ.
    """

    def __init__(self):
        # 1. Ø§ØªØµØ§Ù„ Ø¨Ù‡ Redis
        try:
            self.redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, decode_responses=True, socket_timeout=5)
            self.redis_client.ping()
            logger.info(f"ğŸ“¡ Redis connection successful: {REDIS_HOST}:{REDIS_PORT}")
        except redis.exceptions.ConnectionError as e:
            logger.error(f"âŒ Could not connect to Redis: {e}. Caching feature will be disabled.")
            self.redis_client = None

    # ---------------------------------------------------------
    # 0) ÙˆØ§Ú©Ø´ÛŒ Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Database Fetcher)
    # ---------------------------------------------------------
    def get_unique_symbols_from_db(self) -> List[str]:
        """
        Ø§ÛŒÙ† Ù…ØªØ¯ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯Ù‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ 'Ù…Ø§Ù†ÛŒ'ØŒ 'ÙÙˆÙ„Ø§Ø¯') Ø±Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
        Ú†ÙˆÙ† pytse-client Ø¨Ø§ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ù†Ù‡ Ø¨Ø§ Ú©Ø¯ Ø¹Ø¯Ø¯ÛŒ (TSETMC ID).
        """
        session = get_db_session()
        unique_names = set() # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Set Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
        
        try:
            logger.info("ğŸ—„ï¸ Querying database for watchlist symbol NAMES...")
            

            weekly = session.query(WeeklyWatchlistResult.symbol_name).all()
            for r in weekly: 
                if r.symbol_name: unique_names.add(r.symbol_name)
            

            # Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±: GoldenKeyResult.score > 24
            golden = (
                session.query(GoldenKeyResult.symbol_name)
                .filter(GoldenKeyResult.score > 24)
                .all()
            )

            for r in golden: 
                # ØªÙˆØ¬Ù‡: Ø§Ú¯Ø± symbol_name ØªÙ†Ù‡Ø§ ÙÛŒÙ„Ø¯ Ø¯Ø± Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø§Ø´Ø¯ØŒ r ÛŒÚ© ØªØ§Ù¾Ù„ ÛŒØ§ ÛŒÚ© Ø´ÛŒØ¡ ØªÚ©â€ŒØ¹Ø¶ÙˆÛŒ Ø§Ø³Øª.
                # Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø¢Ù†ØŒ Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø§Ø² r[0] ÛŒØ§ r.symbol_name Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
                # r.symbol_name Ø¯Ø± Ø­Ø§Ù„Øª .all() Ø¯Ø±Ø³Øª Ø§Ø³Øª Ø§Ú¯Ø± ÛŒÚ© Ø´ÛŒØ¡ result Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´ÙˆØ¯.
                if r.symbol_name:
                    unique_names.add(r.symbol_name)
            
            # 3. Potential Buy Queue
            buy_queue = session.query(PotentialBuyQueueResult.symbol_name).all()
            for r in buy_queue: 
                if r.symbol_name: unique_names.add(r.symbol_name)
            
            # 4. Dynamic Support
            dynamic = session.query(DynamicSupportOpportunity.symbol_name).all()
            for r in dynamic: 
                if r.symbol_name: unique_names.add(r.symbol_name)
            
            logger.info(f"âœ… Found {len(unique_names)} unique symbol names (e.g., 'Ù…Ø§Ù†ÛŒ') to monitor.")
            return list(unique_names)
            
        except AttributeError as e:
            logger.error(f"âŒ Database Schema Error: One of your tables assumes 'symbol_name' exists but it might be missing. Details: {e}")
            return []
        except Exception as e:
            logger.error(f"âŒ Database Query Error: {e}")
            return []
        finally:
            session.close()

    # ---------------------------------------------------------
    # ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¬Ø¯ÛŒØ¯: Ø¯Ø±ÛŒØ§ÙØª Ù…Ø·Ù…Ø¦Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ù‚ÛŒÙ‚ÛŒ/Ø­Ù‚ÙˆÙ‚ÛŒ
    # ---------------------------------------------------------
    def _safe_get_trade_summary(self, rt_data, summary_type: str) -> Dict[str, Any]:
        """
        ğŸ’¡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡Ù…ÛŒØ´Ù‡ float ÛŒØ§ int Ù‡Ø³ØªÙ†Ø¯ ØªØ§ Ø®Ø·Ø§ÛŒ NoneType Ø¯Ø± Ø¹Ù…Ù„ÛŒØ§Øª Ø±ÛŒØ§Ø¶ÛŒ Ø±Ø® Ù†Ø¯Ù‡Ø¯.
        """
        attr_name = f'{summary_type}_trade_summary'
        summary = getattr(rt_data, attr_name, None)
    
        # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Dictionary Ø¢Ù…Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        default_values = {
            f'{summary_type}_buy_vol': 0.0,
            f'{summary_type}_buy_count': 0,
            f'{summary_type}_sell_vol': 0.0,
            f'{summary_type}_sell_count': 0,
        }
    
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ summary ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ attributeÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
        if summary and hasattr(summary, 'buy_vol') and hasattr(summary, 'sell_vol'):
            # â— ØªØ¨Ø¯ÛŒÙ„ ØµØ±ÛŒØ­ Ø¨Ù‡ float Ùˆ int Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡
            # Ø§Ø² float() Ùˆ int() Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ù‡Ø± Ù…Ù‚Ø¯Ø§Ø± ØºÛŒØ± Ø¹Ø¯Ø¯ÛŒ (Ù…Ø«Ù„ None) Ú©Ù‡ Ø¨Ø§ or 0.0 Ø¨Ù‡ ØµÙØ± ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡ØŒ 
            # Ø¨Ù‡ Ù†ÙˆØ¹ Ø¯Ø±Ø³ØªÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø´ÙˆØ¯.
            buy_vol = float(summary.buy_vol or 0.0)
            buy_count = int(summary.buy_count or 0)
            sell_vol = float(summary.sell_vol or 0.0)
            sell_count = int(summary.sell_count or 0)
        
            return {
                f'{summary_type}_buy_vol': buy_vol, 
                f'{summary_type}_buy_count': buy_count,
                f'{summary_type}_sell_vol': sell_vol,
                f'{summary_type}_sell_count': sell_count,
            }
        else:
            # Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¢Ø¨Ø¬Ú©Øª summaryØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
            return default_values

    # ---------------------------------------------------------
    # 1) ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ (Live Data Mapper)
    # ---------------------------------------------------------
    def _map_live_data(self, ticker: tse.Ticker) -> Optional[Dict[str, Any]]:
        """
        Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ get_ticker_real_time_info_response Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ 
        Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Null Ø±Ø§ Ø§ÛŒÙ…Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        try:
            # Ø·Ø¨Ù‚ Ù…Ø³ØªÙ†Ø¯Ø§Øª: Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø¨Ø¬Ú©Øª Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
            rt_data = ticker.get_ticker_real_time_info_response()
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù…Ø¬Ø§Ø²/Ù…Ù…Ù†ÙˆØ¹ (State)
            # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ state ÛŒÙ‡ Ø§Ø³ØªØ±ÛŒÙ†Ú¯ Ø§Ø³Øª. Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ ÙÛŒÙ„ØªØ± ÙˆØ¶Ø¹ÛŒØª Ø¯Ø§Ø±ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯.
            
            result = {
                'symbol': ticker.symbol,  # Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ (Ù…Ø«Ù„ ÙÙˆÙ„Ø§Ø¯)
                'symbol_name': ticker.title, # Ù†Ø§Ù… Ú©Ø§Ù…Ù„ Ø´Ø±Ú©Øª
                
                # --- Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ùˆ Ø­Ø¬Ù…â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ: Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 'or 0.0' Ø§ÛŒÙ…Ù†â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ---
                'last_price': rt_data.last_price or 0.0,      # Ù‚ÛŒÙ…Øª Ø¢Ø®Ø±ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡
                'adj_close': rt_data.adj_close or 0.0,        # Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒØ§Ù†ÛŒ
                'open_price': rt_data.open_price or 0.0,
                'yesterday_price': rt_data.yesterday_price or 0.0,
                'high_price': rt_data.high_price or 0.0,
                'low_price': rt_data.low_price or 0.0,
                'volume': rt_data.volume or 0,               # Ø­Ø¬Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
                'value': rt_data.value or 0.0,                 # Ø§Ø±Ø²Ø´ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                'base_volume': ticker.base_volume or 0,      # Ø­Ø¬Ù… Ù…Ø¨Ù†Ø§ Ø§Ø² Ø¢Ø¨Ø¬Ú©Øª Ø§ØµÙ„ÛŒ ticker Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                'count': rt_data.count or 0,                 # ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                
                # --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ§Ø¨Ù„ÙˆØ®ÙˆØ§Ù†ÛŒ (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¹Ø±Ø¶Ù‡ Ùˆ ØªÙ‚Ø§Ø¶Ø§) ---
                'best_demand_price': rt_data.best_demand_price or 0.0, # Ù‚ÛŒÙ…Øª Ø¨Ù‡ØªØ±ÛŒÙ† Ø®Ø±ÛŒØ¯ (Ø³Ø±Ø®Ø·)
                'best_demand_vol': rt_data.best_demand_vol or 0,       # Ø­Ø¬Ù… Ø¨Ù‡ØªØ±ÛŒÙ† Ø®Ø±ÛŒØ¯
                'best_supply_price': rt_data.best_supply_price or 0.0, # Ù‚ÛŒÙ…Øª Ø¨Ù‡ØªØ±ÛŒÙ† ÙØ±ÙˆØ´
                'best_supply_vol': rt_data.best_supply_vol or 0,       # Ø­Ø¬Ù… Ø¨Ù‡ØªØ±ÛŒÙ† ÙØ±ÙˆØ´
                
                # --- Ø­Ù‚ÛŒÙ‚ÛŒ / Ø­Ù‚ÙˆÙ‚ÛŒ (Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø§ÛŒÙ…Ù†) ---
                # Ø·Ø¨Ù‚ Ù…Ø³ØªÙ†Ø¯Ø§ØªØŒ Ø§ÛŒÙ† Ø¢Ø¨Ø¬Ú©Øªâ€ŒÙ‡Ø§ Ø¯Ø§Ø®Ù„ individual_trade_summary Ùˆ corporate_trade_summary Ù‡Ø³ØªÙ†Ø¯
            }
            
            # Ù†Ú¯Ø§Ø´Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ù‚ÛŒÙ‚ÛŒ (Individual)
            result.update(self._safe_get_trade_summary(rt_data, 'individual'))

            # Ù†Ú¯Ø§Ø´Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ù‚ÙˆÙ‚ÛŒ (Corporate)
            result.update(self._safe_get_trade_summary(rt_data, 'corporate'))

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‚Ø¯Ø±Øª Ø®Ø±ÛŒØ¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ (Optional - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ø± Ù„Ø­Ø¸Ù‡)
            # Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ù…ÛŒÙ†Ø¬Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ù†ÛŒØ¯:
            # buy_power = (ind_buy_vol / ind_buy_count) if ind_buy_count > 0 else 0
            
            return result

        except RuntimeError:
            # Ø§ÛŒÙ† Ø§Ø±ÙˆØ± Ø·Ø¨Ù‚ Ù…Ø³ØªÙ†Ø¯Ø§Øª ÛŒØ¹Ù†ÛŒ Ø¯ÛŒØªØ§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª (Ù†Ù…Ø§Ø¯ Ø¨Ø³ØªÙ‡ ÛŒØ§ Ù‚Ø¯ÛŒÙ…ÛŒ)
            logger.warning(f"âš ï¸ Real-time data not available for {ticker.symbol} (Stopped or Old).")
            return None
        except Exception as e:
            # Ø®Ø·Ø§ÛŒ 'unsupported operand type(s) for *: 'NoneType' and 'float'' Ø¯ÛŒÚ¯Ø± Ù†Ø¨Ø§ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø® Ø¯Ù‡Ø¯ØŒ 
            # Ø¨Ù„Ú©Ù‡ Ø¯Ø± Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ ØªØ­Ù„ÛŒÙ„ (ÙØ§Ø² 2) Ú©Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø±Ø® Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
            logger.error(f"âŒ Error mapping data for {ticker.symbol}: {e}")
            return None

    # ---------------------------------------------------------
    # 2) ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ (Main Loop)
    # ---------------------------------------------------------
    def fetch_and_cache_all_realtime(self):
        """
        Ù…ØªØ¯ Ø§ØµÙ„ÛŒ Ú©Ù‡ ØªÙˆØ³Ø· Task Scheduler ÛŒØ§ Loop ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        1. Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø§Ø² DB Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
        2. Ø¯ÛŒØªØ§ÛŒ TSETMC Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
        3. Ø¯Ø± Redis Ú©Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        if not self.redis_client:
            logger.error("âŒ Caching failed: Redis client not initialized.")
            return

        # Ø§Ù„Ù) Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        symbol_list = self.get_unique_symbols_from_db()
        
        if not symbol_list:
            logger.warning("âš ï¸ Watchlist is empty. No symbols to fetch.")
            return

        all_tickers_data = []
        logger.info(f"ğŸ“¡ Starting real-time fetch for {len(symbol_list)} symbols...")

        # Ø¨) Ø¯Ø±ÛŒØ§ÙØª Ø¯ÛŒØªØ§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
        for symbol in symbol_list:
            try:
                # Ø³Ø§Ø®Øª Ø¢Ø¨Ø¬Ú©Øª Ticker
                ticker = tse.Ticker(symbol)
                
                # ÙˆØ§Ú©Ø´ÛŒ Ø¯ÛŒØªØ§ÛŒ Ù…Ù¾ Ø´Ø¯Ù‡
                live_mapped_data = self._map_live_data(ticker)
                
                if live_mapped_data:
                    all_tickers_data.append(live_mapped_data)

            except Exception as e:
                logger.error(f"âŒ Unexpected error processing {symbol}: {e}")
                continue

        # Ø¬) Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis
        if all_tickers_data:
            try:
                # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ ÙØ±Ù…Øª JSON
                self.redis_client.set(REALTIME_CACHE_KEY, json.dumps(all_tickers_data))
                # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Expiration Ù‡Ù… Ø¨Ú¯Ø°Ø§Ø±ÛŒÙ… Ú©Ù‡ Ø¯ÛŒØªØ§ Ø¨ÛŒØ§Øª Ù†Ø´ÙˆØ¯ (Ù…Ø«Ù„Ø§ 2 Ø¯Ù‚ÛŒÙ‚Ù‡)
                self.redis_client.expire(REALTIME_CACHE_KEY, 120) 
                
                logger.info(f"âœ… Successfully cached real-time data for {len(all_tickers_data)} symbols in Redis.")
            except Exception as e:
                logger.error(f"âŒ Failed to write data to Redis: {e}")
        else:
            logger.warning("âš ï¸ No valid live data was collected to cache.")

# --- (Ø¨Ø®Ø´ ØªØ³Øª Ø¯Ø³ØªÛŒ) ---
if __name__ == "__main__":
    # ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
    logging.basicConfig(level=logging.INFO)
    
    orchestrator = Phase1Orchestrator()
    orchestrator.fetch_and_cache_all_realtime()