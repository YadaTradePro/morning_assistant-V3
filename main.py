# main.py
# Ø³Ø±ÙˆØ± Ø§ØµÙ„ÛŒ Flask Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ÙØ§Ø² Û² Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„

from flask import Flask, jsonify
import requests
from datetime import datetime
from sqlalchemy import text
from db_connector import get_db_session
from analysis_engine import analyze_symbol_combined, escape_markdown
from notifier import TelegramNotifier
import os
import logging
import json
import redis
from dotenv import load_dotenv
from zoneinfo import ZoneInfo
from typing import Dict, Any, Optional

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
load_dotenv()

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Flask
app = Flask(__name__)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

notifier = TelegramNotifier()
TEHRAN_TZ = ZoneInfo("Asia/Tehran")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Redis (Ù…Ø´Ø§Ø¨Ù‡ Orchestrator)
REALTIME_CACHE_KEY = "market:realtime:tickers" 
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", 6379))

LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

# ==========================
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (Helper Functions)
# ==========================

def fetch_potential_symbols_with_phase1_data(db_session) -> Dict[str, Any]:
    """
    ÙˆØ§Ú©Ø´ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ Ø§Ø² Ø¬Ø¯Ø§ÙˆÙ„ ÙØ§Ø² Û± (GoldenKey, Watchlist, BuyQueue)
    Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡.
    """
    # Ú©ÙˆØ¦Ø±ÛŒ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ db_connector.py (Ù…Ø®ØµÙˆØµØ§Ù‹ jentry_date)
    query = text("""
        WITH LatestTech AS (
            SELECT *, ROW_NUMBER() OVER(PARTITION BY symbol_id ORDER BY jdate DESC) as rn
            FROM technical_indicator_data
        ),
        LatestCandle AS (
            SELECT *, ROW_NUMBER() OVER(PARTITION BY symbol_id ORDER BY jdate DESC) as rn
            FROM candlestick_pattern_detection
        ),
        AllCandidates AS (
            SELECT symbol_id, score AS golden_key_score, jdate, 'GoldenKey' AS source_table FROM golden_key_results WHERE score > 26
            UNION
            SELECT symbol_id, probability_percent AS golden_key_score, jdate, 'BuyQueue' AS source_table FROM potential_buy_queue_results WHERE probability_percent > 50
            UNION
            SELECT symbol_id, 100 as golden_key_score, jentry_date AS jdate, 'Watchlist' AS source_table FROM weekly_watchlist_results
            UNION
            SELECT symbol_id, 100 as golden_key_score, analysis_date As jdate, 'DynamicSupport' AS source_table FROM dynamic_support_opportunities
        )
        SELECT DISTINCT
            ac.symbol_id,
            csd.symbol_name,
            ac.golden_key_score,
            ac.source_table,
            tech.RSI,
            tech.halftrend_signal,
            candle.pattern_name
        FROM AllCandidates ac
        INNER JOIN comprehensive_symbol_data csd ON ac.symbol_id = csd.symbol_id
        LEFT JOIN LatestTech tech ON ac.symbol_id = tech.symbol_id AND tech.rn = 1
        LEFT JOIN LatestCandle candle ON ac.symbol_id = candle.symbol_id AND candle.rn = 1
        ORDER BY ac.golden_key_score DESC
        LIMIT 100;
    """)
    
    try:
        result = db_session.execute(query)
        # Ø®Ø±ÙˆØ¬ÛŒ: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯ symbol_id
        symbols_data = {row.symbol_id: dict(row._mapping) for row in result}
        logger.info(f"âœ… Found {len(symbols_data)} potential symbols from DB.")
        return symbols_data
    except Exception as e:
        logger.error(f"âŒ SQL Query Failed: {e}")
        return {}

def fetch_live_market_data_from_cache() -> Optional[Dict[str, Dict[str, Any]]]:
    """
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ Ø±Ø§ Ø§Ø² Redis Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯.
    Ø®Ø±ÙˆØ¬ÛŒ: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ù‡ Ú©Ù„ÛŒØ¯ Ø¢Ù† 'Ù†Ø§Ù… Ù†Ù…Ø§Ø¯' (ÙØ§Ø±Ø³ÛŒ) Ø§Ø³Øª.
    """
    try:
        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, decode_responses=True, socket_timeout=2)
        raw_data = r.get(REALTIME_CACHE_KEY)
        
        if not raw_data:
            logger.warning("âš ï¸ Redis cache is empty. Is the Orchestrator running?")
            return None
        
        data_list = json.loads(raw_data)
        # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª Ø¨Ù‡ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯ Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ (Ù…Ø«Ù„Ø§Ù‹ 'ÙÙˆÙ„Ø§Ø¯')
        return {item['symbol']: item for item in data_list if item.get('symbol')}
        
    except Exception as e:
        logger.error(f"âŒ Redis Error: {e}")
        return None

# ==========================
# ØªØ§Ø¨Ø¹ Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯ (Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯)
# ==========================

def save_json_log(alerts):
    """
    ğŸ’¡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯ Ø¨Ø§ Ù†Ø§Ù… Ø±ÙˆØ² Ø¬Ø§Ø±ÛŒØŒ Ø­ØªÛŒ Ø§Ú¯Ø± alerts Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯ØŒ 
    ØªØ§ Dashboard Ù…Ø·Ù…Ø¦Ù† Ø¨Ø§Ø´Ø¯ Ú©Ù‡ ÙØ±Ø¢ÛŒÙ†Ø¯ ØªØ­Ù„ÛŒÙ„ Ø§Ù…Ø±ÙˆØ² Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    """
    # â— Ø§ÛŒÙ† Ø´Ø±Ø· Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯: if not alerts: return 
    
    now = datetime.now(TEHRAN_TZ)
    # 1. Ù†Ø§Ù… ÙØ§ÛŒÙ„: phase2_alerts_YYYYMMDD_HHMM.json
    # Ø§Ú¯Ø± Ø¯Ø± ÛŒÚ© Ø¯Ù‚ÛŒÙ‚Ù‡ Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯ØŒ ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ù…Ø´Ú©Ù„ÛŒ Ù†ÛŒØ³Øª.
    filename = os.path.join(LOG_DIR, f"phase2_alerts_{now.strftime('%Y%m%d_%H%M')}.json")
    
    # 2. Ø³Ø§Ø®ØªØ§Ø±: { 'timestamp': '...', 'alerts': [...] }
    log_data = {
        "timestamp": now.strftime('%Y-%m-%d %H:%M:%S'),
        "alerts_count": len(alerts),
        "alerts": alerts 
    }
    
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“ Dashboard Log Saved ({len(alerts)} alerts): {filename}")
    except Exception as e:
        logger.error(f"âŒ Failed to save log: {e}")


# ==========================
# Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ ØªØ­Ù„ÛŒÙ„ (Core Logic)
# ==========================

def process_market_analysis():
    """
    Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ: ØªØ±Ú©ÛŒØ¨ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ø±Ø¯ÛŒØ³ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù….
    """
    now = datetime.now(TEHRAN_TZ)
    logger.info("ğŸ”„ Starting Analysis Cycle...")
    
    db_session = get_db_session()
    alerts_sent = 0
    
    try:
        # 1. ÙˆØ§Ú©Ø´ÛŒ Ø¯ÛŒØªØ§ Ø§Ø² DB
        potential_symbols = fetch_potential_symbols_with_phase1_data(db_session)
        if not potential_symbols:
            return {"status": "skipped", "message": "No symbols in watchlist DB"}

        # 2. ÙˆØ§Ú©Ø´ÛŒ Ø¯ÛŒØªØ§ Ø§Ø² Redis
        live_data = fetch_live_market_data_from_cache()
        if not live_data:
            return {"status": "error", "message": "No live data in Redis"}

        strong_buy_alerts = []

        # 3. Ø­Ù„Ù‚Ù‡ ØªØ­Ù„ÛŒÙ„
        for p1_id, p1_data in potential_symbols.items():
            sym_name = p1_data.get('symbol_name')
            
            if sym_name and sym_name in live_data:
                live_ticker = live_data[sym_name]
                analysis_result = analyze_symbol_combined(live_ticker, p1_data)
                
                if analysis_result.get("is_strong_buy"):
                    strong_buy_alerts.append(analysis_result)
            else:
                continue

        # 4. Ø§Ø±Ø³Ø§Ù„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…
        if strong_buy_alerts:
            message_lines = [f"ğŸš¨ **Strong Buy Signals Detected** ({now.strftime('%H:%M')})\n"]
            
            for alert in strong_buy_alerts:
                # â— ØªÙˆØ¬Ù‡: Ø¢Ø¯Ø±Ø³â€ŒØ¯Ù‡ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ ÙÙ„Øª Ø´Ø¯Ù‡ (Ù…Ø«Ù„ power_ratio Ùˆ target)
                # Ø§Ø² Ø¢Ù†Ø¬Ø§ÛŒÛŒ Ú©Ù‡ analysis_engine.py Ø±Ø§ Ù…Ø³Ø·Ø­ Ú©Ø±Ø¯ÛŒÙ…ØŒ Ø§ÛŒÙ† Ø§ØµÙ„Ø§Ø­ Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª.
                row = (
                    f"ğŸ’ *{escape_markdown(alert.get('symbol_name', 'N/A'))}*\n"
                    f"ğŸ“ˆ Score: `{alert.get('score')}` | Power: `{alert.get('power_ratio')}`\n"
                    f"ğŸ’° Price: `{alert.get('last_price')}` | Target: `{alert.get('target')}`\n"
                    f"ğŸ“œ Reasons: {', '.join(alert.get('reasons', []))}\n"
                    f"------------------"
                )
                message_lines.append(row)
            
            full_msg = "\n".join(message_lines)
            
            try:
                notifier.send_message(full_msg)
                logger.info(f"ğŸ“¨ Sent {len(strong_buy_alerts)} alerts to Telegram.")
            except Exception as e:
                logger.error(f"âŒ Failed to send Telegram message: {e}")
            
            alerts_sent = len(strong_buy_alerts)
        
        # 5. Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯ Ø¬ÛŒØ³ÙˆÙ† (ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡)
        save_json_log(strong_buy_alerts)
        
        return {
            "status": "success", 
            "symbols_checked": len(potential_symbols),
            "alerts_generated": alerts_sent
        }

    finally:
        db_session.close()

# ==========================
# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Flask (Routes)
# ==========================

@app.route('/')
def index():
    return "<h1>ğŸ¤– Morning Assistant API is Running</h1><p>Use /run to trigger analysis.</p>"

@app.route('/run', methods=['GET', 'POST'])
def manual_run():
    """
    Ø§ÛŒÙ† Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ (ØªÙˆØ³Ø· Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ Ø®Ø§Ø±Ø¬ÛŒ) ÛŒØ§ Ø¯Ø³ØªÛŒ ØµØ¯Ø§ Ø¨Ø²Ù†ÛŒØ¯.
    """
    result = process_market_analysis()
    return jsonify(result)

@app.route('/health')
def health_check():
    # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø±Ø¯ÛŒØ³
    try:
        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, socket_timeout=1)
        r.ping()
        redis_status = "UP"
    except:
        redis_status = "DOWN"
        
    return jsonify({"status": "ok", "redis": redis_status, "time": datetime.now().isoformat()})

if __name__ == "__main__":
    # Ø§Ø¬Ø±Ø§ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 5000
    logger.info("ğŸš€ Flask Server Starting on port 5000...")
    app.run(host='0.0.0.0', port=5000, debug=False)
